{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74ed3661-1d1e-41a1-814f-dc02fe8e5b92",
   "metadata": {},
   "source": [
    "# Simple Hybrid recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8b8718-f933-444d-824d-af293226b02f",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58dadfa6-3995-4d3a-9a7a-73046ef417cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb01677-27f4-4e95-9b92-3268ccff767f",
   "metadata": {},
   "source": [
    "## Data pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f88f1c2e-eb41-4016-8f5a-d4866a492171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "def preprocess_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    # Map author_id (user) and hotel_id (item) to continuous indices\n",
    "    user_mapping = {id: idx for idx, id in enumerate(df['author_id'].unique())}\n",
    "    item_mapping = {id: idx for idx, id in enumerate(df['hotel_id'].unique())}\n",
    "\n",
    "    df['author_id'] = df['author_id'].map(user_mapping)\n",
    "    df['hotel_id'] = df['hotel_id'].map(item_mapping)\n",
    "\n",
    "    # Extract metadata from property_dict\n",
    "    df['property_dict'] = df['property_dict'].apply(lambda x: json.loads(x) if isinstance(x, str) else {})\n",
    "    metadata = df['property_dict'].apply(pd.Series).fillna(0)\n",
    "    df = pd.concat([df, metadata], axis=1)\n",
    "\n",
    "    num_users = len(user_mapping)\n",
    "    num_items = len(item_mapping)\n",
    "    num_attributes = metadata.shape[1]\n",
    "\n",
    "    return df, num_users, num_items, num_attributes\n",
    "\n",
    "file_path = \"../data/combined_filtered_reviews.csv\"\n",
    "df, num_users, num_items, num_attributes = preprocess_data(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bbb1cf-ec70-4a50-907e-8515018284e1",
   "metadata": {},
   "source": [
    "## Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47f4d30f-ae00-4c44-aa30-d494daf39f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Dataset\n",
    "class HybridDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.users = torch.tensor(df['author_id'].values, dtype=torch.long)\n",
    "        self.items = torch.tensor(df['hotel_id'].values, dtype=torch.long)\n",
    "        self.ratings = torch.tensor(df['rating'].values, dtype=torch.float32)\n",
    "        self.attributes = torch.tensor(df.iloc[:, 7:].values, dtype=torch.float32)  # Assuming metadata starts at 7th column\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.users[idx], self.items[idx], self.ratings[idx], self.attributes[idx]\n",
    "\n",
    "# Split data into train and test sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_dataset = HybridDataset(train_df)\n",
    "test_dataset = HybridDataset(test_df)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797c0bd9-56ab-4b5f-95f2-c9f6c5f9e8ba",
   "metadata": {},
   "source": [
    "## Hybrid model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8903c9de-3f0e-458b-951f-33a48437a6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Hybrid Model\n",
    "class HybridNCF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, num_attributes, latent_dim=50):\n",
    "        super(HybridNCF, self).__init__()\n",
    "        # Embedding layers\n",
    "        self.user_embedding = nn.Embedding(num_users, latent_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, latent_dim)\n",
    "        \n",
    "        # Metadata processing\n",
    "        self.metadata_fc = nn.Sequential(\n",
    "            nn.Linear(num_attributes, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        # Fully connected layers for recommendation\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(latent_dim * 2 + 32, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, user, item, metadata):\n",
    "        user_emb = self.user_embedding(user)\n",
    "        item_emb = self.item_embedding(item)\n",
    "        metadata_emb = self.metadata_fc(metadata)\n",
    "        x = torch.cat([user_emb, item_emb, metadata_emb], dim=-1)\n",
    "        return self.fc(x).squeeze()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d125bb38-d8c8-40b4-abc6-e98da8560451",
   "metadata": {},
   "source": [
    "## Training setup using CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0291ebcd-37bf-42ae-a6f9-50fd2f3257f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HybridNCF(num_users, num_items, num_attributes).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa76240-0adf-4d1e-b24b-1f1162033ce2",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d1ffd3d-23d2-41c6-b5a6-5c227d84cbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.5472\n",
      "Epoch 2/10, Train Loss: 0.4061\n",
      "Epoch 3/10, Train Loss: 0.3755\n",
      "Epoch 4/10, Train Loss: 0.3597\n",
      "Epoch 5/10, Train Loss: 0.3499\n",
      "Epoch 6/10, Train Loss: 0.3415\n",
      "Epoch 7/10, Train Loss: 0.3345\n",
      "Epoch 8/10, Train Loss: 0.3274\n",
      "Epoch 9/10, Train Loss: 0.3201\n",
      "Epoch 10/10, Train Loss: 0.3122\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for user, item, rating, metadata in train_loader:\n",
    "        user, item, rating, metadata = user.to(device), item.to(device), rating.to(device), metadata.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(user, item, metadata)\n",
    "        loss = criterion(predictions, rating)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b856e31b-1570-4426-a269-77d954ed0eca",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7199c50-2261-4aa5-8e19-03697dc78e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss (MSE): 0.5191\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for user, item, rating, metadata in data_loader:\n",
    "            user, item, rating, metadata = user.to(device), item.to(device), rating.to(device), metadata.to(device)\n",
    "            predictions = model(user, item, metadata)\n",
    "            loss = criterion(predictions, rating)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "test_loss = evaluate_model(model, test_loader)\n",
    "print(f\"Test Loss (MSE): {test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ec163c-6e7c-49a4-b0e7-7cb36646880d",
   "metadata": {},
   "source": [
    "## RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fb47ac4-5e51-4f01-960e-3022dc583a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.7205\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def compute_rmse(model, data_loader):\n",
    "    model.eval()\n",
    "    mse_loss = 0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for user, item, rating, metadata in data_loader:\n",
    "            user, item, rating, metadata = user.to(device), item.to(device), rating.to(device), metadata.to(device)\n",
    "            predictions = model(user, item, metadata)\n",
    "            mse_loss += torch.sum((predictions - rating) ** 2).item()\n",
    "            total_samples += len(rating)\n",
    "    rmse = math.sqrt(mse_loss / total_samples)\n",
    "    return rmse\n",
    "\n",
    "test_rmse = compute_rmse(model, test_loader)\n",
    "print(f\"Test RMSE: {test_rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25023bfe-c972-4a50-8c6f-74f56927d052",
   "metadata": {},
   "source": [
    "## Export model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fbb5f98-cb37-4ba8-9cc9-bedd2350bb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'hybrid_model.pth'\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"hybrid_model.pth\")\n",
    "print(\"Model saved as 'hybrid_model.pth'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
