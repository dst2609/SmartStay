{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ddf16e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting datatable\n",
      "  Obtaining dependency information for datatable from https://files.pythonhosted.org/packages/bb/c5/987fcb116df777d2573c8918b7d7bb391405fa0ca3ed209238bf447b7aac/datatable-1.1.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading datatable-1.1.0-cp311-cp311-win_amd64.whl.metadata (1.8 kB)\n",
      "Downloading datatable-1.1.0-cp311-cp311-win_amd64.whl (4.7 MB)\n",
      "   ---------------------------------------- 0.0/4.7 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.3/4.7 MB 7.0 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 1.0/4.7 MB 13.3 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 2.1/4.7 MB 16.6 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 2.1/4.7 MB 16.6 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 3.1/4.7 MB 16.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.2/4.7 MB 15.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.2/4.7 MB 15.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.7/4.7 MB 13.7 MB/s eta 0:00:00\n",
      "Installing collected packages: datatable\n",
      "Successfully installed datatable-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install datatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a877a201-5b56-4e06-99f2-86d526f37b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import csv\n",
    "\n",
    "# def json_to_csv(input_file, output_file):\n",
    "#     with open(input_file, 'r') as infile, open(output_file, 'w', newline='') as outfile:\n",
    "#         fieldnames = ['hotel_url', 'author', 'date', 'rating', 'title', 'text', 'property_dict']\n",
    "#         csv_writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "#         csv_writer.writeheader()\n",
    "\n",
    "#         for line in infile:\n",
    "#             data = json.loads(line)\n",
    "#             csv_writer.writerow(data)\n",
    "\n",
    "# # Example usage:\n",
    "# input_file = '../hotelRec/HotelRec.txt'\n",
    "# output_file = 'hotel_reviews.csv'\n",
    "# json_to_csv(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3aa5a8c9-5f9d-4ec5-9877-7a1b791f13b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50264531\n"
     ]
    }
   ],
   "source": [
    "num_rows = len(df.index)\n",
    "print(num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcea02cc-6b54-4249-896a-ba0a5230bea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           hotel_url        author  \\\n",
      "0  Hotel_Review-g194775-d1121769-Reviews-Hotel_Ba...  violettaf340   \n",
      "1  Hotel_Review-g194775-d1121769-Reviews-Hotel_Ba...     Lagaiuzza   \n",
      "2  Hotel_Review-g194775-d1121769-Reviews-Hotel_Ba...    ashleyn763   \n",
      "3  Hotel_Review-g194775-d1121769-Reviews-Hotel_Ba...   DavideMauro   \n",
      "4  Hotel_Review-g194775-d1121769-Reviews-Hotel_Ba...      Alemma11   \n",
      "\n",
      "                  date  rating  \\\n",
      "0  2019-01-01T00:00:00     5.0   \n",
      "1  2016-01-01T00:00:00     5.0   \n",
      "2  2014-10-01T00:00:00     5.0   \n",
      "3  2014-08-01T00:00:00     5.0   \n",
      "4  2013-08-01T00:00:00     4.0   \n",
      "\n",
      "                                              title  \\\n",
      "0                                      Xmas holiday   \n",
      "1                                Baltic, what else?   \n",
      "2                           Excellent in every way!   \n",
      "3                The house of your family's holiday   \n",
      "4  A paradise for children (and parents, of course)   \n",
      "\n",
      "                                                text  \\\n",
      "0  We went here with our kids for Xmas holiday an...   \n",
      "1  We have spent in this hotel our summer holiday...   \n",
      "2  I visited Hotel Baltic with my husband for som...   \n",
      "3  I've travelled quite a numbers of hotels but t...   \n",
      "4  We decided for this family holiday destination...   \n",
      "\n",
      "                                       property_dict  \n",
      "0                                                 {}  \n",
      "1                                                 {}  \n",
      "2    {'service': 5.0, 'location': 5.0, 'value': 5.0}  \n",
      "3  {'service': 5.0, 'cleanliness': 5.0, 'sleep qu...  \n",
      "4  {'sleep quality': 3.0, 'value': 4.0, 'rooms': ...  \n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "df = dd.read_csv('../data/hotel_reviews.csv')\n",
    "# Perform computations on the Dask DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28d930a0-fff3-4a43-b2f4-5c8b01419159",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "import pandas as pd\n",
    "\n",
    "def create_label_encoders(df: pd.DataFrame) -> Tuple[Dict[str, int], Dict[str, int]]:\n",
    "    \"\"\"\n",
    "    Create label encoders (mapping dictionaries) for hotel_url and author columns\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input dataframe containing hotel_url and author columns\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[Dict[str, int], Dict[str, int]]: Hotel URL and author mapping dictionaries\n",
    "    \"\"\"\n",
    "    # Create mapping dictionaries\n",
    "    hotel_mapping = {url: idx for idx, url in enumerate(df['hotel_url'].unique())}\n",
    "    author_mapping = {author: idx for idx, author in enumerate(df['author'].unique())}\n",
    "    \n",
    "    return hotel_mapping, author_mapping\n",
    "\n",
    "def encode_hotel_author(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Encode hotel_url and author columns to integer values\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input dataframe containing hotel_url and author columns\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with encoded columns added\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original dataframe\n",
    "    df_encoded = df.copy()\n",
    "    \n",
    "    # Create mapping dictionaries\n",
    "    hotel_mapping, author_mapping = create_label_encoders(df)\n",
    "    \n",
    "    # Add encoded columns\n",
    "    df_encoded['hotel_id'] = df_encoded['hotel_url'].map(hotel_mapping)\n",
    "    df_encoded['author_id'] = df_encoded['author'].map(author_mapping)\n",
    "    \n",
    "    # Print some statistics\n",
    "    print(f\"Number of unique hotels: {len(hotel_mapping)}\")\n",
    "    print(f\"Number of unique authors: {len(author_mapping)}\")\n",
    "    \n",
    "    return df_encoded, hotel_mapping, author_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abf8c33c-509a-4fab-a477-0da0546d1de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique hotels: 365057\n",
      "Number of unique authors: 21891404\n",
      "\n",
      "Sample of encoded data:\n",
      "                                           hotel_url  hotel_id        author  \\\n",
      "0  Hotel_Review-g194775-d1121769-Reviews-Hotel_Ba...         0  violettaf340   \n",
      "1  Hotel_Review-g194775-d1121769-Reviews-Hotel_Ba...         0     Lagaiuzza   \n",
      "2  Hotel_Review-g194775-d1121769-Reviews-Hotel_Ba...         0    ashleyn763   \n",
      "3  Hotel_Review-g194775-d1121769-Reviews-Hotel_Ba...         0   DavideMauro   \n",
      "4  Hotel_Review-g194775-d1121769-Reviews-Hotel_Ba...         0      Alemma11   \n",
      "\n",
      "   author_id  \n",
      "0          0  \n",
      "1          1  \n",
      "2          2  \n",
      "3          3  \n",
      "4          4  \n"
     ]
    }
   ],
   "source": [
    "# Encode the data\n",
    "df_encoded, hotel_mapping, author_mapping = encode_hotel_author(df)\n",
    "\n",
    "# Now df_encoded contains new columns 'hotel_id' and 'author_id'\n",
    "# The original columns are preserved\n",
    "\n",
    "# Example usage:\n",
    "print(\"\\nSample of encoded data:\")\n",
    "print(df_encoded[['hotel_url', 'hotel_id', 'author', 'author_id']].head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f0c5cb9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Metadata inference failed in `drop_by_shallow_copy`.\n\nYou have supplied a custom function and Dask is unable to \ndetermine the type of output that that function returns. \n\nTo resolve this please provide a meta= keyword.\nThe docstring of the Dask function you ran should have more information.\n\nOriginal error is below:\n------------------------\nKeyError(\"['hotel_url', 'author'] not found in axis\")\n\nTraceback:\n---------\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\utils.py\", line 193, in raise_on_meta_error\n    yield\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\core.py\", line 6876, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\utils.py\", line 774, in drop_by_shallow_copy\n    df2.drop(columns=columns, inplace=True, errors=errors)\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py\", line 331, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py\", line 5399, in drop\n    return super().drop(\n           ^^^^^^^^^^^^^\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py\", line 331, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\", line 4505, in drop\n    obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\", line 4546, in _drop_axis\n    new_axis = axis.drop(labels, errors=errors)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 6934, in drop\n    raise KeyError(f\"{list(labels[mask])} not found in axis\")\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\utils.py:193\u001b[0m, in \u001b[0;36mraise_on_meta_error\u001b[1;34m(funcname, udf)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 193\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\core.py:6876\u001b[0m, in \u001b[0;36m_emulate\u001b[1;34m(func, udf, *args, **kwargs)\u001b[0m\n\u001b[0;32m   6875\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m raise_on_meta_error(funcname(func), udf\u001b[38;5;241m=\u001b[39mudf), check_numeric_only_deprecation():\n\u001b[1;32m-> 6876\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m_extract_meta(args, \u001b[38;5;28;01mTrue\u001b[39;00m), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_extract_meta(kwargs, \u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\utils.py:774\u001b[0m, in \u001b[0;36mdrop_by_shallow_copy\u001b[1;34m(df, columns, errors)\u001b[0m\n\u001b[0;32m    773\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [columns]\n\u001b[1;32m--> 774\u001b[0m df2\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39mcolumns, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m    775\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df2\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:5399\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5262\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5263\u001b[0m \u001b[38;5;124;03mDrop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5264\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5397\u001b[0m \u001b[38;5;124;03m        weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5398\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m-> 5399\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[0;32m   5400\u001b[0m     labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m   5401\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   5402\u001b[0m     index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   5403\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   5404\u001b[0m     level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   5405\u001b[0m     inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[0;32m   5406\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   5407\u001b[0m )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4505\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4505\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_drop_axis(labels, axis, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4546\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4545\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4546\u001b[0m     new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4547\u001b[0m indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6934\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6933\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6934\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6935\u001b[0m indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['hotel_url', 'author'] not found in axis\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Remove hotel_url and author columns\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_encoded \u001b[38;5;241m=\u001b[39m df_encoded\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhotel_url\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthor\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# keeping rows with rating value, removing empty rating rows\u001b[39;00m\n\u001b[0;32m      4\u001b[0m df_encoded \u001b[38;5;241m=\u001b[39m df_encoded[df_encoded[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnotnull()]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\core.py:5599\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, columns, errors)\u001b[0m\n\u001b[0;32m   5595\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmap_partitions(\n\u001b[0;32m   5596\u001b[0m         drop_by_shallow_copy, columns, errors\u001b[38;5;241m=\u001b[39merrors, enforce_metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   5597\u001b[0m     )\n\u001b[0;32m   5598\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 5599\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmap_partitions(\n\u001b[0;32m   5600\u001b[0m         drop_by_shallow_copy, labels, errors\u001b[38;5;241m=\u001b[39merrors, enforce_metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   5601\u001b[0m     )\n\u001b[0;32m   5602\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m   5603\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDrop currently only works for axis=1 or when columns is not None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   5604\u001b[0m )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\core.py:1006\u001b[0m, in \u001b[0;36m_Frame.map_partitions\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;129m@insert_meta_param_description\u001b[39m(pad\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m)\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap_partitions\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    880\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply Python function on each DataFrame partition.\u001b[39;00m\n\u001b[0;32m    881\u001b[0m \n\u001b[0;32m    882\u001b[0m \u001b[38;5;124;03m    Note that the index and divisions are assumed to remain unchanged.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1004\u001b[0m \u001b[38;5;124;03m    None as the division.\u001b[39;00m\n\u001b[0;32m   1005\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1006\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m map_partitions(func, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\core.py:6946\u001b[0m, in \u001b[0;36mmap_partitions\u001b[1;34m(func, meta, enforce_metadata, transform_divisions, align_dataframes, *args, **kwargs)\u001b[0m\n\u001b[0;32m   6939\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   6940\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. If you don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt want the partitions to be aligned, and are \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6941\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalling `map_partitions` directly, pass `align_dataframes=False`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6942\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   6944\u001b[0m dfs \u001b[38;5;241m=\u001b[39m [df \u001b[38;5;28;01mfor\u001b[39;00m df \u001b[38;5;129;01min\u001b[39;00m args \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(df, _Frame)]\n\u001b[1;32m-> 6946\u001b[0m meta \u001b[38;5;241m=\u001b[39m _get_meta_map_partitions(args, dfs, func, kwargs, meta, parent_meta)\n\u001b[0;32m   6947\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(arg, Scalar) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args):\n\u001b[0;32m   6948\u001b[0m     layer \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   6949\u001b[0m         (name, \u001b[38;5;241m0\u001b[39m): (\n\u001b[0;32m   6950\u001b[0m             apply,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6954\u001b[0m         )\n\u001b[0;32m   6955\u001b[0m     }\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\core.py:7057\u001b[0m, in \u001b[0;36m_get_meta_map_partitions\u001b[1;34m(args, dfs, func, kwargs, meta, parent_meta)\u001b[0m\n\u001b[0;32m   7053\u001b[0m     parent_meta \u001b[38;5;241m=\u001b[39m dfs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_meta\n\u001b[0;32m   7054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m meta \u001b[38;5;129;01mis\u001b[39;00m no_default:\n\u001b[0;32m   7055\u001b[0m     \u001b[38;5;66;03m# Use non-normalized kwargs here, as we want the real values (not\u001b[39;00m\n\u001b[0;32m   7056\u001b[0m     \u001b[38;5;66;03m# delayed values)\u001b[39;00m\n\u001b[1;32m-> 7057\u001b[0m     meta \u001b[38;5;241m=\u001b[39m _emulate(func, \u001b[38;5;241m*\u001b[39margs, udf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   7058\u001b[0m     meta_is_emulated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   7059\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\core.py:6875\u001b[0m, in \u001b[0;36m_emulate\u001b[1;34m(func, udf, *args, **kwargs)\u001b[0m\n\u001b[0;32m   6870\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_emulate\u001b[39m(func, \u001b[38;5;241m*\u001b[39margs, udf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   6871\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   6872\u001b[0m \u001b[38;5;124;03m    Apply a function using args / kwargs. If arguments contain dd.DataFrame /\u001b[39;00m\n\u001b[0;32m   6873\u001b[0m \u001b[38;5;124;03m    dd.Series, using internal cache (``_meta``) for calculation\u001b[39;00m\n\u001b[0;32m   6874\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 6875\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m raise_on_meta_error(funcname(func), udf\u001b[38;5;241m=\u001b[39mudf), check_numeric_only_deprecation():\n\u001b[0;32m   6876\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m_extract_meta(args, \u001b[38;5;28;01mTrue\u001b[39;00m), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_extract_meta(kwargs, \u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\contextlib.py:155\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    153\u001b[0m     value \u001b[38;5;241m=\u001b[39m typ()\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen\u001b[38;5;241m.\u001b[39mthrow(typ, value, traceback)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\utils.py:214\u001b[0m, in \u001b[0;36mraise_on_meta_error\u001b[1;34m(funcname, udf)\u001b[0m\n\u001b[0;32m    205\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal error is below:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m------------------------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    212\u001b[0m )\n\u001b[0;32m    213\u001b[0m msg \u001b[38;5;241m=\u001b[39m msg\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m funcname \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mrepr\u001b[39m(e), tb)\n\u001b[1;32m--> 214\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Metadata inference failed in `drop_by_shallow_copy`.\n\nYou have supplied a custom function and Dask is unable to \ndetermine the type of output that that function returns. \n\nTo resolve this please provide a meta= keyword.\nThe docstring of the Dask function you ran should have more information.\n\nOriginal error is below:\n------------------------\nKeyError(\"['hotel_url', 'author'] not found in axis\")\n\nTraceback:\n---------\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\utils.py\", line 193, in raise_on_meta_error\n    yield\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\core.py\", line 6876, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\utils.py\", line 774, in drop_by_shallow_copy\n    df2.drop(columns=columns, inplace=True, errors=errors)\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py\", line 331, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py\", line 5399, in drop\n    return super().drop(\n           ^^^^^^^^^^^^^\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py\", line 331, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\", line 4505, in drop\n    obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\", line 4546, in _drop_axis\n    new_axis = axis.drop(labels, errors=errors)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 6934, in drop\n    raise KeyError(f\"{list(labels[mask])} not found in axis\")\n"
     ]
    }
   ],
   "source": [
    "# Remove hotel_url and author columns\n",
    "df_encoded = df_encoded.drop(['hotel_url', 'author'], axis=1)\n",
    "# keeping rows with rating value, removing empty rating rows\n",
    "df_encoded = df_encoded[df_encoded['rating'].notnull()]\n",
    "\n",
    "# # Step 1: Get value counts for authors\n",
    "# print(\"Counting reviews per author...\")\n",
    "# author_counts = df_encoded['author_id'].value_counts().compute()\n",
    "\n",
    "# # Step 2: Get list of authors with more than 20 reviews\n",
    "# print(\"Getting list of frequent authors...\")\n",
    "# frequent_authors = list(author_counts[author_counts >= 20].index)\n",
    "# print(f\"Found {len(frequent_authors)} authors with 20+ reviews\")\n",
    "\n",
    "# # Step 3: Filter and save in chunks\n",
    "# print(\"Filtering and saving data...\")\n",
    "# df_frequent = df_encoded[df_encoded['author_id'].isin(frequent_authors)]\n",
    "\n",
    "# # Save to CSV in chunks\n",
    "# df_frequent.to_csv('../data/hotel_reviews_frequent_reviewers_*.csv', \n",
    "#                   single_file=True,  # Combines all parts into a single file\n",
    "#                   compute=True,      # Actually performs the computation\n",
    "#                   encoding='utf-8',\n",
    "#                   index=False)\n",
    "\n",
    "# print(\"Done! Checking file size...\")\n",
    "\n",
    "# # Check results\n",
    "# import os\n",
    "# import glob\n",
    "\n",
    "# # Get the saved file(s)\n",
    "# saved_file = glob.glob('../data/hotel_reviews_frequent_reviewers_*.csv')[0]\n",
    "# file_size = os.path.getsize(saved_file) / (1024 * 1024)  # Convert to MB\n",
    "# print(f\"File saved as: {saved_file}\")\n",
    "# print(f\"File size: {file_size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "236108c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing npartitions...\n",
      "Computing author frequencies...\n",
      "[########################################] | 100% Completed | 3hr 31m\n",
      "[########################################] | 100% Completed | 3hr 31m\n",
      "[########################################] | 100% Completed | 3hr 31m\n",
      "Computing frequent authors...\n",
      "Found 189992 frequent authors\n",
      "Filtering and saving data...\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m df_frequent \u001b[38;5;241m=\u001b[39m df_encoded[df_encoded\u001b[38;5;241m.\u001b[39mauthor_id\u001b[38;5;241m.\u001b[39misin(frequent_authors)]\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Save with optimized settings\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m df_frequent\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/hotel_reviews_frequent_reviewers_*.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     27\u001b[0m                    single_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     28\u001b[0m                    compute\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     29\u001b[0m                    encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     30\u001b[0m                    index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     31\u001b[0m                    compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     32\u001b[0m                    blocksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m64MB\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing complete!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\core.py:1840\u001b[0m, in \u001b[0;36m_Frame.to_csv\u001b[1;34m(self, filename, **kwargs)\u001b[0m\n\u001b[0;32m   1837\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"See dd.to_csv docstring for more information\"\"\"\u001b[39;00m\n\u001b[0;32m   1838\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_csv\n\u001b[1;32m-> 1840\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m to_csv(\u001b[38;5;28mself\u001b[39m, filename, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py:944\u001b[0m, in \u001b[0;36mto_csv\u001b[1;34m(df, filename, single_file, encoding, mode, name_function, compression, compute, scheduler, storage_options, header_first_partition_only, compute_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    942\u001b[0m value \u001b[38;5;241m=\u001b[39m to_csv_chunk(dfs[\u001b[38;5;241m0\u001b[39m], first_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    943\u001b[0m append_mode \u001b[38;5;241m=\u001b[39m mode\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 944\u001b[0m append_file \u001b[38;5;241m=\u001b[39m open_file(filename, mode\u001b[38;5;241m=\u001b[39mappend_mode, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfile_options)\n\u001b[0;32m    945\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheader\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    946\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m dfs[\u001b[38;5;241m1\u001b[39m:]:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\fsspec\\core.py:419\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(urlpath, mode, compression, encoding, errors, protocol, newline, **kwargs)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen\u001b[39m(\n\u001b[0;32m    370\u001b[0m     urlpath,\n\u001b[0;32m    371\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    378\u001b[0m ):\n\u001b[0;32m    379\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Given a path or paths, return one ``OpenFile`` object.\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \n\u001b[0;32m    381\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;124;03m    ``OpenFile`` object.\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m open_files(\n\u001b[0;32m    420\u001b[0m         urlpath\u001b[38;5;241m=\u001b[39m[urlpath],\n\u001b[0;32m    421\u001b[0m         mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m    422\u001b[0m         compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m    423\u001b[0m         encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m    424\u001b[0m         errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    425\u001b[0m         protocol\u001b[38;5;241m=\u001b[39mprotocol,\n\u001b[0;32m    426\u001b[0m         newline\u001b[38;5;241m=\u001b[39mnewline,\n\u001b[0;32m    427\u001b[0m         expand\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    428\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    429\u001b[0m     )[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\fsspec\\core.py:194\u001b[0m, in \u001b[0;36mOpenFiles.__getitem__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, item):\n\u001b[1;32m--> 194\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(item)\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, \u001b[38;5;28mslice\u001b[39m):\n\u001b[0;32m    196\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m OpenFiles(out, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode, fs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfs)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# optimized version to keep only authors with 20+ reviews\n",
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "# Enable progress bar\n",
    "pbar = ProgressBar()\n",
    "pbar.register()\n",
    "\n",
    "# Optimize partitions based on memory\n",
    "print(\"Computing npartitions...\")\n",
    "npartitions = 25\n",
    "df_encoded = df_encoded.repartition(npartitions=npartitions)\n",
    "\n",
    "# Compute author counts using optimized aggregation\n",
    "print(\"Computing author frequencies...\")\n",
    "author_counts = df_encoded.author_id.value_counts(split_every=8).compute()\n",
    "print(\"Computing frequent authors...\")\n",
    "frequent_authors = set(author_counts[author_counts >= 20].index)\n",
    "print(f\"Found {len(frequent_authors)} frequent authors\")\n",
    "\n",
    "# Filter with optimized settings\n",
    "print(\"Filtering and saving data...\")\n",
    "df_frequent = df_encoded[df_encoded.author_id.isin(frequent_authors)]\n",
    "\n",
    "# Save with optimized settings\n",
    "df_frequent.to_csv('../data/hotel_reviews_frequent_reviewers_*.csv',\n",
    "                   single_file=True,\n",
    "                   compute=True,\n",
    "                   encoding='utf-8',\n",
    "                   index=False,\n",
    "                   compression='gzip',\n",
    "                   blocksize='64MB')\n",
    "\n",
    "print(\"Processing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9749052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 486.53 s\n",
      "[########################################] | 100% Completed | 486.63 s\n",
      "[########################################] | 100% Completed | 486.73 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>property_dict</th>\n",
       "      <th>hotel_id</th>\n",
       "      <th>author_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017-03-01T00:00:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Natural Luxury</td>\n",
       "      <td>The property is surrounded by trees, which are...</td>\n",
       "      <td>{'service': 5.0, 'sleep quality': 5.0, 'value'...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2016-01-01T00:00:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Loved out stay, a lot of character</td>\n",
       "      <td>Well, this hotel stands out from the crowd, so...</td>\n",
       "      <td>{'rooms': 5.0, 'service': 5.0, 'cleanliness': ...</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2015-07-01T00:00:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Really nice staff, yummy breakfast and the mon...</td>\n",
       "      <td>The pousada is like 30 minute walk to the cent...</td>\n",
       "      <td>{'rooms': 5.0, 'service': 5.0, 'value': 5.0}</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2017-05-01T00:00:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Gorgeous agriturismo with beautiful grounds an...</td>\n",
       "      <td>We made a brief stop to visit the 12th century...</td>\n",
       "      <td>{'location': 4.0}</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2017-01-01T00:00:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Really enjoyed the experience</td>\n",
       "      <td>Recently spent 2 nights here and used it as a ...</td>\n",
       "      <td>{'rooms': 5.0, 'service': 5.0, 'sleep quality'...</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   date  rating  \\\n",
       "8   2017-03-01T00:00:00     5.0   \n",
       "12  2016-01-01T00:00:00     5.0   \n",
       "14  2015-07-01T00:00:00     5.0   \n",
       "24  2017-05-01T00:00:00     4.0   \n",
       "25  2017-01-01T00:00:00     5.0   \n",
       "\n",
       "                                                title  \\\n",
       "8                                      Natural Luxury   \n",
       "12                 Loved out stay, a lot of character   \n",
       "14  Really nice staff, yummy breakfast and the mon...   \n",
       "24  Gorgeous agriturismo with beautiful grounds an...   \n",
       "25                      Really enjoyed the experience   \n",
       "\n",
       "                                                 text  \\\n",
       "8   The property is surrounded by trees, which are...   \n",
       "12  Well, this hotel stands out from the crowd, so...   \n",
       "14  The pousada is like 30 minute walk to the cent...   \n",
       "24  We made a brief stop to visit the 12th century...   \n",
       "25  Recently spent 2 nights here and used it as a ...   \n",
       "\n",
       "                                        property_dict  hotel_id  author_id  \n",
       "8   {'service': 5.0, 'sleep quality': 5.0, 'value'...         1          8  \n",
       "12  {'rooms': 5.0, 'service': 5.0, 'cleanliness': ...         1         12  \n",
       "14       {'rooms': 5.0, 'service': 5.0, 'value': 5.0}         1          8  \n",
       "24                                  {'location': 4.0}         2         23  \n",
       "25  {'rooms': 5.0, 'service': 5.0, 'sleep quality'...         2         24  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_frequent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d668f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3505, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\cyclo\\AppData\\Local\\Temp\\ipykernel_14516\\1072007154.py\", line 5, in <module>\n",
      "    df_frequent.to_csv('../data/filtered_reviews.csv', index=False)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\core.py\", line 1840, in to_csv\n",
      "    return to_csv(self, filename, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py\", line 939, in to_csv\n",
      "    dfs = df.to_delayed()\n",
      "          ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\core.py\", line 1903, in to_delayed\n",
      "    graph = self.__dask_optimize__(graph, self.__dask_keys__())\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\optimize.py\", line 27, in optimize\n",
      "    dsk = dsk.cull(set(keys))\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\dask\\highlevelgraph.py\", line 719, in cull\n",
      "    culled_layer, culled_deps = layer.cull(output_keys, all_ext_keys)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\dask\\highlevelgraph.py\", line 131, in cull\n",
      "    {k: self.get_dependencies(k, all_hlg_keys) for k in self.keys()},\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\dask\\highlevelgraph.py\", line 131, in <dictcomp>\n",
      "    {k: self.get_dependencies(k, all_hlg_keys) for k in self.keys()},\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\dask\\highlevelgraph.py\", line 165, in get_dependencies\n",
      "    return keys_in_tasks(all_hlg_keys, [self[key]])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\dask\\core.py\", line -1, in keys_in_tasks\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3445, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3527, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2062, in showtraceback\n",
      "    def showtraceback(self, exc_tuple=None, filename=None, tb_offset=None,\n",
      "    \n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2102, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1310, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1199, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1071, in structured_traceback\n",
      "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 978, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 878, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 712, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\stack_data\\core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\stack_data\\core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\stack_data\\core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\executing\\executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Now df_frequent contains only entries where the author has more than 20 reviews\n",
    "# Export the filtered DataFrame to a CSV file\n",
    "df_frequent.to_csv('../data/filtered_reviews.csv', index=False)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8611ee76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 3hr 44m\n",
      "[########################################] | 100% Completed | 3hr 44m\n",
      "[########################################] | 100% Completed | 3hr 44m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\cyclo\\\\OneDrive\\\\Documents\\\\GitHub\\\\SmartStay\\\\src\\\\filtered_reviews.csv\\\\00.part',\n",
       " 'C:\\\\Users\\\\cyclo\\\\OneDrive\\\\Documents\\\\GitHub\\\\SmartStay\\\\src\\\\filtered_reviews.csv\\\\01.part',\n",
       " 'C:\\\\Users\\\\cyclo\\\\OneDrive\\\\Documents\\\\GitHub\\\\SmartStay\\\\src\\\\filtered_reviews.csv\\\\02.part',\n",
       " 'C:\\\\Users\\\\cyclo\\\\OneDrive\\\\Documents\\\\GitHub\\\\SmartStay\\\\src\\\\filtered_reviews.csv\\\\03.part',\n",
       " 'C:\\\\Users\\\\cyclo\\\\OneDrive\\\\Documents\\\\GitHub\\\\SmartStay\\\\src\\\\filtered_reviews.csv\\\\04.part',\n",
       " 'C:\\\\Users\\\\cyclo\\\\OneDrive\\\\Documents\\\\GitHub\\\\SmartStay\\\\src\\\\filtered_reviews.csv\\\\05.part',\n",
       " 'C:\\\\Users\\\\cyclo\\\\OneDrive\\\\Documents\\\\GitHub\\\\SmartStay\\\\src\\\\filtered_reviews.csv\\\\06.part',\n",
       " 'C:\\\\Users\\\\cyclo\\\\OneDrive\\\\Documents\\\\GitHub\\\\SmartStay\\\\src\\\\filtered_reviews.csv\\\\07.part',\n",
       " 'C:\\\\Users\\\\cyclo\\\\OneDrive\\\\Documents\\\\GitHub\\\\SmartStay\\\\src\\\\filtered_reviews.csv\\\\08.part',\n",
       " 'C:\\\\Users\\\\cyclo\\\\OneDrive\\\\Documents\\\\GitHub\\\\SmartStay\\\\src\\\\filtered_reviews.csv\\\\09.part',\n",
       " 'C:\\\\Users\\\\cyclo\\\\OneDrive\\\\Documents\\\\GitHub\\\\SmartStay\\\\src\\\\filtered_reviews.csv\\\\10.part',\n",
       " 'C:\\\\Users\\\\cyclo\\\\OneDrive\\\\Documents\\\\GitHub\\\\SmartStay\\\\src\\\\filtered_reviews.csv\\\\11.part',\n",
       " 'C:\\\\Users\\\\cyclo\\\\OneDrive\\\\Documents\\\\GitHub\\\\SmartStay\\\\src\\\\filtered_reviews.csv\\\\12.part',\n",
       " 'C:\\\\Users\\\\cyclo\\\\OneDrive\\\\Documents\\\\GitHub\\\\SmartStay\\\\src\\\\filtered_reviews.csv\\\\13.part',\n",
       " 'C:\\\\Users\\\\cyclo\\\\OneDrive\\\\Documents\\\\GitHub\\\\SmartStay\\\\src\\\\filtered_reviews.csv\\\\14.part',\n",
       " 'C:\\\\Users\\\\cyclo\\\\OneDrive\\\\Documents\\\\GitHub\\\\SmartStay\\\\src\\\\filtered_reviews.csv\\\\15.part',\n",
       " 'C:\\\\Users\\\\cyclo\\\\OneDrive\\\\Documents\\\\GitHub\\\\SmartStay\\\\src\\\\filtered_reviews.csv\\\\16.part',\n",
       " 'C:\\\\Users\\\\cyclo\\\\OneDrive\\\\Documents\\\\GitHub\\\\SmartStay\\\\src\\\\filtered_reviews.csv\\\\17.part',\n",
       " 'C:\\\\Users\\\\cyclo\\\\OneDrive\\\\Documents\\\\GitHub\\\\SmartStay\\\\src\\\\filtered_reviews.csv\\\\18.part',\n",
       " 'C:\\\\Users\\\\cyclo\\\\OneDrive\\\\Documents\\\\GitHub\\\\SmartStay\\\\src\\\\filtered_reviews.csv\\\\19.part',\n",
       " 'C:\\\\Users\\\\cyclo\\\\OneDrive\\\\Documents\\\\GitHub\\\\SmartStay\\\\src\\\\filtered_reviews.csv\\\\20.part',\n",
       " 'C:\\\\Users\\\\cyclo\\\\OneDrive\\\\Documents\\\\GitHub\\\\SmartStay\\\\src\\\\filtered_reviews.csv\\\\21.part',\n",
       " 'C:\\\\Users\\\\cyclo\\\\OneDrive\\\\Documents\\\\GitHub\\\\SmartStay\\\\src\\\\filtered_reviews.csv\\\\22.part',\n",
       " 'C:\\\\Users\\\\cyclo\\\\OneDrive\\\\Documents\\\\GitHub\\\\SmartStay\\\\src\\\\filtered_reviews.csv\\\\23.part',\n",
       " 'C:\\\\Users\\\\cyclo\\\\OneDrive\\\\Documents\\\\GitHub\\\\SmartStay\\\\src\\\\filtered_reviews.csv\\\\24.part']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_size = 50000\n",
    "\n",
    "# Export the filtered DataFrame to CSV in chunks\n",
    "df_frequent.to_csv('filtered_reviews.csv', index=False, chunksize=chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54afca6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Path to the folder containing the .part files\n",
    "folder_path = './filtered_reviews.csv'  # folder path\n",
    "\n",
    "# Output CSV file\n",
    "output_file = 'combined_filtered_reviews.csv'\n",
    "\n",
    "# Open the output file in write mode with UTF-8 encoding\n",
    "with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "    first_file = True  # To track the first file for including headers\n",
    "\n",
    "    # Iterate through all .part files in the folder (sorted if needed)\n",
    "    for part_file in sorted(os.listdir(folder_path)):\n",
    "        if part_file.endswith('.part'):  # Only process .part files\n",
    "            with open(os.path.join(folder_path, part_file), 'r', encoding='utf-8') as infile:\n",
    "                if first_file:\n",
    "                    # Write the header from the first file\n",
    "                    outfile.write(infile.read())\n",
    "                    first_file = False\n",
    "                else:\n",
    "                    # Skip the header for subsequent files\n",
    "                    next(infile)  # Skip the first line\n",
    "                    outfile.write(infile.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db13e22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 922.12 ms\n",
      "[########################################] | 100% Completed | 1.02 s\n",
      "[########################################] | 100% Completed | 1.11 s\n",
      "                   date  rating  \\\n",
      "0   2017-03-01T00:00:00     5.0   \n",
      "1   2016-01-01T00:00:00     5.0   \n",
      "2   2015-07-01T00:00:00     5.0   \n",
      "3   2017-05-01T00:00:00     4.0   \n",
      "4   2017-01-01T00:00:00     5.0   \n",
      "5   2016-10-01T00:00:00     5.0   \n",
      "6   2016-10-01T00:00:00     4.0   \n",
      "7   2016-10-01T00:00:00     4.0   \n",
      "8   2016-05-01T00:00:00     5.0   \n",
      "9   2016-05-01T00:00:00     4.0   \n",
      "10  2015-09-01T00:00:00     5.0   \n",
      "11  2015-06-01T00:00:00     5.0   \n",
      "12  2015-10-01T00:00:00     5.0   \n",
      "13  2015-09-01T00:00:00     5.0   \n",
      "14  2019-02-01T00:00:00     3.0   \n",
      "\n",
      "                                                title  \\\n",
      "0                                      Natural Luxury   \n",
      "1                  Loved out stay, a lot of character   \n",
      "2   Really nice staff, yummy breakfast and the mon...   \n",
      "3   Gorgeous agriturismo with beautiful grounds an...   \n",
      "4                       Really enjoyed the experience   \n",
      "5                                          Delightful   \n",
      "6   Real castle - out of discussion. Must see, per...   \n",
      "7             Gorgeous location, friendly agriturismo   \n",
      "8                                      Excellent stay   \n",
      "9       We would try to only stay in the castle rooms   \n",
      "10                           How to feel like a King!   \n",
      "11                                         Delightful   \n",
      "12    Just stay here when you're visiting Lampedusa!!   \n",
      "13                               Great Find in Centre   \n",
      "14                       Good rooms, painful internet   \n",
      "\n",
      "                                                 text  \\\n",
      "0   The property is surrounded by trees, which are...   \n",
      "1   Well, this hotel stands out from the crowd, so...   \n",
      "2   The pousada is like 30 minute walk to the cent...   \n",
      "3   We made a brief stop to visit the 12th century...   \n",
      "4   Recently spent 2 nights here and used it as a ...   \n",
      "5   We totally enjoyed our granary cozy room with ...   \n",
      "6   I must start from the fact that it is a real c...   \n",
      "7   Great agriturismo, in a fabulous setting. Cast...   \n",
      "8   Doesn't matter if you stay inside the castle o...   \n",
      "9   Found this place as a last minute opportunity ...   \n",
      "10  From the moment I saw the castle from the road...   \n",
      "11  I never realized how exciting a castle could b...   \n",
      "12  Location: 5 min. drive from airport. You can h...   \n",
      "13  Hotel owners are very accommodating from picki...   \n",
      "14  I stayed two nights at the hotel on my own whi...   \n",
      "\n",
      "                                        property_dict  hotel_id  author_id  \n",
      "0   {'service': 5.0, 'sleep quality': 5.0, 'value'...         1          8  \n",
      "1   {'rooms': 5.0, 'service': 5.0, 'cleanliness': ...         1         12  \n",
      "2        {'rooms': 5.0, 'service': 5.0, 'value': 5.0}         1          8  \n",
      "3                                   {'location': 4.0}         2         23  \n",
      "4   {'rooms': 5.0, 'service': 5.0, 'sleep quality'...         2         24  \n",
      "5                                                  {}         2         25  \n",
      "6   {'service': 4.0, 'cleanliness': 4.0, 'value': ...         2         26  \n",
      "7                                                  {}         2         28  \n",
      "8                                                  {}         2         31  \n",
      "9   {'service': 5.0, 'cleanliness': 5.0, 'location...         2         32  \n",
      "10  {'service': 5.0, 'location': 5.0, 'sleep quali...         2         34  \n",
      "11  {'rooms': 5.0, 'service': 5.0, 'cleanliness': ...         2         37  \n",
      "12  {'service': 5.0, 'cleanliness': 5.0, 'location...         3         48  \n",
      "13  {'service': 5.0, 'cleanliness': 5.0, 'sleep qu...         3         49  \n",
      "14       {'rooms': 3.0, 'service': 5.0, 'value': 3.0}         4         57  \n"
     ]
    }
   ],
   "source": [
    "df_new = dd.read_csv('combined_filtered_reviews.csv')\n",
    "# Perform computations on the Dask DataFrame\n",
    "print(df_new.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26b4df2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
