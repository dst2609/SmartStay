{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"4jQ-9wQtOqsA"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import torch\n","from torch import nn, optim\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error"]},{"cell_type":"markdown","metadata":{"id":"jbIoEZc8P4Bu"},"source":["# Load Data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":136691,"status":"ok","timestamp":1733015190315,"user":{"displayName":"Long Haitao","userId":"18227905063443674720"},"user_tz":480},"id":"UQIDVTjuPJjl","outputId":"96719abc-9bcc-4604-94ea-a85664cfce2d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","Loading data successfully\n"]}],"source":["from google.colab import drive\n","\n","# Mount your Google Drive\n","drive.mount('/content/drive')\n","\n","# Replace with the actual file path in your Google Drive\n","file_path = '/content/drive/MyDrive/CMPE-256-Shared/data/combined_filtered_reviews.csv' #  Replace 'your_folder_name' and 'your_file.csv'\n","\n","try:\n","  # Read the CSV file into a pandas DataFrame\n","  # typically it will cost around3 mins.\n","  df = pd.read_csv(file_path)\n","\n","  # Print or process the DataFrame\n","  print(\"Loading data successfully\")\n","\n","except FileNotFoundError:\n","  print(f\"Error: File not found at {file_path}. Please check the file path.\")\n","except pd.errors.ParserError:\n","  print(f\"Error: Could not parse the file at {file_path}.  Is it a valid CSV file?\")\n","except Exception as e:\n","  print(f\"An unexpected error occurred: {e}\")"]},{"cell_type":"markdown","metadata":{"id":"RTGIhwHFsVvB"},"source":["# Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":178},"executionInfo":{"elapsed":44,"status":"ok","timestamp":1733015190315,"user":{"displayName":"Long Haitao","userId":"18227905063443674720"},"user_tz":480},"id":"2u4XzMYwm0UZ","outputId":"23d61964-b7f3-4f7d-d4fe-b6c66908c50a"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","    </tr>\n","    <tr>\n","      <th>author_id</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>202</th>\n","      <td>1193017</td>\n","    </tr>\n","    <tr>\n","      <th>1504</th>\n","      <td>23889</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"],"text/plain":["author_id\n","202     1193017\n","1504      23889\n","Name: count, dtype: int64"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# prompt: 我希望统计author_id频率出现第一高和第二高的author_id，并打印出它们的频率。无需import，\n","\n","author_id_counts = df['author_id'].value_counts()\n","top_two_author_ids = author_id_counts.nlargest(2)\n","top_two_author_ids"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E1h7ytFGug2I"},"outputs":[],"source":["author_id_mapping = {id: idx for idx, id in enumerate(df['author_id'].unique())}\n","hotel_id_mapping = {id: idx for idx, id in enumerate(df['hotel_id'].unique())}\n","\n","df['author_id'] = df['author_id'].map(author_id_mapping)\n","df['hotel_id'] = df['hotel_id'].map(hotel_id_mapping)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y8jJ3mmOfgUi"},"outputs":[],"source":["from datetime import datetime\n","TODAY = datetime.now()\n","df['date'] = pd.to_datetime(df['date'], format=\"%Y-%m-%dT%H:%M:%S\")\n","df['date interval'] = (TODAY - df['date']).dt.days"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":188},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1733015192825,"user":{"displayName":"Long Haitao","userId":"18227905063443674720"},"user_tz":480},"id":"AVMppxyFf1JE","outputId":"0f5aa82c-c206-4c62-c92d-96e4971ab5b6"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"summary":"{\n  \"name\": \"df\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2015-08-01 00:00:00\",\n        \"max\": \"2015-08-01 00:00:00\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"2015-08-01 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 4.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Nice downtown hotel\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Overall a very good stay at the Hotel Palomar. Parking is hard but I guess that is to be expected in a downtown area. Check in was easy and the staff helpful. The room was large and comfortable, modern in style. A very good value for the price. The hotel has a happy hour with free bad wine and snack which is nice. There is also a restaurant inside the hotel and an outdoor pool. The best thing for me is that the hotel is within walking distance of all sorts of fun things to do like bars, restaurants and the baseball stadium.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"property_dict\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"{'service': 4.0, 'rooms': 4.0, 'cleanliness': 4.0}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hotel_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 50836,\n        \"max\": 50836,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          50836\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"author_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 6837,\n        \"max\": 6837,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          6837\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date interval\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 3410,\n        \"max\": 3410,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3410\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}","type":"dataframe"},"text/html":["\n","  <div id=\"df-8a2fd8d8-c0b1-487c-a213-1e2ecc16426f\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date</th>\n","      <th>rating</th>\n","      <th>title</th>\n","      <th>text</th>\n","      <th>property_dict</th>\n","      <th>hotel_id</th>\n","      <th>author_id</th>\n","      <th>date interval</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2335950</th>\n","      <td>2015-08-01</td>\n","      <td>4.0</td>\n","      <td>Nice downtown hotel</td>\n","      <td>Overall a very good stay at the Hotel Palomar....</td>\n","      <td>{'service': 4.0, 'rooms': 4.0, 'cleanliness': ...</td>\n","      <td>50836</td>\n","      <td>6837</td>\n","      <td>3410</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8a2fd8d8-c0b1-487c-a213-1e2ecc16426f')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-8a2fd8d8-c0b1-487c-a213-1e2ecc16426f button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-8a2fd8d8-c0b1-487c-a213-1e2ecc16426f');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"text/plain":["              date  rating                title  \\\n","2335950 2015-08-01     4.0  Nice downtown hotel   \n","\n","                                                      text  \\\n","2335950  Overall a very good stay at the Hotel Palomar....   \n","\n","                                             property_dict  hotel_id  \\\n","2335950  {'service': 4.0, 'rooms': 4.0, 'cleanliness': ...     50836   \n","\n","         author_id  date interval  \n","2335950       6837           3410  "]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["df.sample(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":210},"executionInfo":{"elapsed":362,"status":"ok","timestamp":1733015193182,"user":{"displayName":"Long Haitao","userId":"18227905063443674720"},"user_tz":480},"id":"c2RyMkO71Slf","outputId":"f5b6e7c8-2522-41fb-d7e7-a106e24e7c43"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>hotel_id</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>author_id</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>rating</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>date interval</th>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"],"text/plain":["hotel_id         0\n","author_id        0\n","rating           0\n","date interval    0\n","dtype: int64"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# prompt: 我想check hotel_id author_id rating 以及date interval这四栏是否有missing value\n","\n","# Check for missing values in specified columns\n","missing_values = df[['hotel_id', 'author_id', 'rating', 'date interval']].isnull().sum()\n","missing_values"]},{"cell_type":"markdown","metadata":{"id":"_42GFjSHsZtd"},"source":["# Input Data preparation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1733015193183,"user":{"displayName":"Long Haitao","userId":"18227905063443674720"},"user_tz":480},"id":"Bq7YQ3fm1_Lf","outputId":"6466ed89-6af0-48a8-8367-e1f471c30eb7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n"]}],"source":["device_name = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Using device: {device_name}\")\n","DEVICE = torch.device(device_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rMQWMJLl0YNU"},"outputs":[],"source":["#DEVICE = torch.device(\"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7OimGWJwQd_3"},"outputs":[],"source":["users = torch.tensor(df['author_id'].values, dtype=torch.long, device=DEVICE)\n","items = torch.tensor(df['hotel_id'].values, dtype=torch.long, device=DEVICE)\n","ratings = torch.tensor(df['rating'].values, dtype=torch.float32, device=DEVICE)\n","date_intervals = torch.tensor(df['date interval'].values, dtype=torch.long, device=DEVICE)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"60TKdZVLRAmL"},"outputs":[],"source":["num_users = len(author_id_mapping)\n","num_items = len(hotel_id_mapping)\n","num_factors = 6"]},{"cell_type":"markdown","metadata":{"id":"9T8JgD15c2Pv"},"source":["# MF GPU version"]},{"cell_type":"markdown","metadata":{"id":"ii45h6Zeksjw"},"source":["## Data Split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5s4NXYMHPtmY"},"outputs":[],"source":["class RatingDataset(Dataset):\n","    def __init__(self, users, items, ratings):\n","        self.users = users\n","        self.items = items\n","        self.ratings = ratings\n","\n","    def __len__(self):\n","        return len(self.ratings)\n","\n","    def __getitem__(self, idx):\n","        return self.users[idx], self.items[idx], self.ratings[idx]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1a_LXtHfzoJr"},"outputs":[],"source":["# 划分数据\n","train_indices, test_indices = train_test_split(range(len(df)), test_size=0.2, random_state=42)\n","\n","# 创建训练和测试数据集\n","train_dataset = RatingDataset(users[train_indices], items[train_indices], ratings[train_indices])\n","test_dataset = RatingDataset(users[test_indices], items[test_indices], ratings[test_indices])\n","\n","# DataLoader\n","train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AY2gpoTi9EAM"},"outputs":[],"source":["#for user, item, rating in train_loader:\n","#    assert user.is_cuda and item.is_cuda and rating.is_cuda, \"Data is not on GPU\"\n"]},{"cell_type":"markdown","metadata":{"id":"S63TeM-O93uu"},"source":["## Model Definition"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ub_Z0IKwoIRB"},"outputs":[],"source":["class GPUMF(nn.Module):\n","    def __init__(self, num_users, num_items, num_factors):\n","        super(GPUMF, self).__init__()\n","        self.user_factors = nn.Embedding(num_users, num_factors)\n","        self.item_factors = nn.Embedding(num_items, num_factors)\n","        self.user_biases = nn.Embedding(num_users, 1)\n","        self.item_biases = nn.Embedding(num_items, 1)\n","        self.global_bias = nn.Parameter(torch.tensor(0.0))\n","\n","        nn.init.xavier_uniform_(self.user_factors.weight)\n","        nn.init.xavier_uniform_(self.item_factors.weight)\n","        nn.init.zeros_(self.user_biases.weight)\n","        nn.init.zeros_(self.item_biases.weight)\n","        nn.init.zeros_(self.global_bias)\n","\n","        self.device = DEVICE\n","\n","        # 打印设备信息\n","        print(f\"Model is running on {self.device}.\")\n","\n","        # 如果在 GPU 上运行，打印更多 GPU 信息\n","        if self.device.type == 'cuda':\n","            print(f\"Running on {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n","            print(f\"Total GPU Memory: {torch.cuda.get_device_properties(self.device).total_memory / 1e9:.2f} GB\")\n","            print(f\"GPU Memory Allocated: {torch.cuda.memory_allocated(self.device) / 1e6:.2f} MB\")\n","            print(f\"GPU Memory Cached: {torch.cuda.memory_reserved(self.device) / 1e6:.2f} MB\")\n","\n","    def forward(self, user, item):\n","        user_embedding = self.user_factors(user)\n","        item_embedding = self.item_factors(item)\n","        user_b = self.user_biases(user).flatten()\n","        item_b = self.item_biases(item).flatten()\n","        preds = (user_embedding * item_embedding).sum(1) + user_b + item_b + self.global_bias\n","        return preds\n","\n","    def fit(self, data_loader, epochs, lr, reg):\n","        self.to(self.device)\n","        self.train()\n","        optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n","        criterion = nn.MSELoss()\n","\n","        for epoch in range(epochs):\n","            for user, item, rating in data_loader:\n","                user = user.to(self.device)\n","                item = item.to(self.device)\n","                rating = rating.to(self.device)\n","                optimizer.zero_grad()\n","                prediction = self(user, item)\n","                l2_reg = reg * (self.user_biases.weight.norm(2) + self.item_biases.weight.norm(2) + self.global_bias.norm(2))\n","                loss = criterion(prediction, rating) + l2_reg\n","                loss.backward()\n","                optimizer.step()\n","            print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n","\n","    def predict(self, user, item):\n","        self.eval()\n","        with torch.no_grad():\n","            prediction = self(user, item)\n","            return prediction.item()\n"]},{"cell_type":"markdown","metadata":{"id":"R99Fq-8nkScc"},"source":["## Run"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1733020870289,"user":{"displayName":"Long Haitao","userId":"18227905063443674720"},"user_tz":480},"id":"3inmBzbDoibS","outputId":"cb106a2a-9e97-4a65-ad57-0441af719b99"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model is running on cuda.\n","Running on Tesla T4\n","Total GPU Memory: 15.84 GB\n","GPU Memory Allocated: 537.34 MB\n","GPU Memory Cached: 694.16 MB\n"]}],"source":["model = GPUMF(num_users, num_items, num_factors)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":896561,"status":"ok","timestamp":1733021766844,"user":{"displayName":"Long Haitao","userId":"18227905063443674720"},"user_tz":480},"id":"cEWugQWjyrWS","outputId":"b985626c-0a0f-439d-c8a5-d7c55fde547b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1, Loss: 5.976485252380371\n","Epoch 2, Loss: 1.5466524362564087\n","Epoch 3, Loss: 1.1320040225982666\n","Epoch 4, Loss: 0.8018453121185303\n","Epoch 5, Loss: 0.8630028963088989\n","Epoch 6, Loss: 0.7495215535163879\n","Epoch 7, Loss: 0.869253396987915\n","Epoch 8, Loss: 0.9113022685050964\n"]}],"source":["model.fit(train_loader, epochs=6, lr=0.0003, reg=0.02)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qDkiYDUJjiOv"},"outputs":[],"source":["def calculate_rmse(model, data_loader):\n","    model.eval()\n","    predictions, ratings = [], []\n","    with torch.no_grad():\n","        for user, item, rating in data_loader:\n","            prediction = model(user, item)\n","            predictions.append(prediction.cpu().numpy())\n","            ratings.append(rating.cpu().numpy())\n","    predictions = np.concatenate(predictions)\n","    ratings = np.concatenate(ratings)\n","    return np.sqrt(mean_squared_error(ratings, predictions))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24147,"status":"ok","timestamp":1733021790977,"user":{"displayName":"Long Haitao","userId":"18227905063443674720"},"user_tz":480},"id":"6NxMVG9AshJx","outputId":"2d05c3ea-f6a8-4d87-8ee8-ba7f9438f67f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test RMSE: 0.9037210941314697\n"]}],"source":["rmse = calculate_rmse(model, test_loader)\n","print(f\"Test RMSE: {rmse}\")"]},{"cell_type":"markdown","metadata":{"id":"G0pPP8igUMVE"},"source":["# Time Decay MF"]},{"cell_type":"markdown","metadata":{"id":"d_btcQGCQHZr"},"source":["## Data Split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IWsqWxHwqTXA"},"outputs":[],"source":["# prompt: # prompt: 我要做一个比较复杂的data split，要求如下：针对每一个author_id，其对应了若干行。按照train size 0.8以及test size 0.2划分。但是划分不是随机的，而是根据date interval来划分。将date interval比较大的划分至train dataset，date interval比较小的划分至test dataset。无需import。最后返回的是对应的indices。使用groupby 似乎更快一些。\n","\n","def split_data_by_date(df, train_size=0.8):\n","    train_indices = []\n","    test_indices = []\n","\n","    for author_id, group in df.groupby('author_id'):\n","        group_sorted = group.sort_values('date interval', ascending=False)\n","        split_point = int(len(group_sorted) * train_size)\n","        train_indices.extend(group_sorted.index[:split_point].tolist())\n","        test_indices.extend(group_sorted.index[split_point:].tolist())\n","\n","    return train_indices, test_indices"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xPRKHKs_hnog"},"outputs":[],"source":["class RatingDataset(Dataset):\n","    def __init__(self, users, items, ratings, timestamps):\n","        self.users = users\n","        self.items = items\n","        self.ratings = ratings\n","        self.date_intervals = date_intervals\n","\n","    def __len__(self):\n","        return len(self.ratings)\n","\n","    def __getitem__(self, idx):\n","        return self.users[idx], self.items[idx], self.ratings[idx], self.date_intervals[idx]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UsPa9Rooqu6u"},"outputs":[],"source":["# 划分数据\n","#train_indices, test_indices = train_test_split(range(len(df)), test_size=0.2, random_state=42)\n","train_indices, test_indices = split_data_by_date(df)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ljg1aXozrFQc"},"outputs":[],"source":["# 创建训练和测试数据集\n","train_dataset = RatingDataset(users[train_indices], items[train_indices], ratings[train_indices], date_intervals[train_indices])\n","test_dataset = RatingDataset(users[test_indices], items[test_indices], ratings[test_indices], date_intervals[test_indices])\n","\n","# DataLoader\n","train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"WfYQ8w2OQSKp"},"source":["## Model Definition"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xJMEIUeER15S"},"outputs":[],"source":["# 定义时间衰减函数\n","def time_decay(date_interval, lamda):\n","    return torch.exp(-lamda * date_interval)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s8Fp2wRZSDKF"},"outputs":[],"source":["# MF模型类\n","class TimeDecayMF(nn.Module):\n","    def __init__(self, num_users, num_items, num_factors):\n","        super(TimeDecayMF, self).__init__()\n","        self.user_factors = nn.Embedding(num_users, num_factors)\n","        self.item_factors = nn.Embedding(num_items, num_factors)\n","        self.user_biases = nn.Embedding(num_users, 1)\n","        self.item_biases = nn.Embedding(num_items, 1)\n","        self.global_bias = nn.Parameter(torch.tensor(0.0))\n","\n","        nn.init.xavier_uniform_(self.user_factors.weight)\n","        nn.init.xavier_uniform_(self.item_factors.weight)\n","        nn.init.zeros_(self.user_biases.weight)\n","        nn.init.zeros_(self.item_biases.weight)\n","        nn.init.zeros_(self.global_bias)\n","\n","        self.device = DEVICE\n","\n","        # 打印设备信息\n","        print(f\"Model is running on {self.device}.\")\n","\n","        # 如果在 GPU 上运行，打印更多 GPU 信息\n","        if self.device.type == 'cuda':\n","            print(f\"Running on {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n","            print(f\"Total GPU Memory: {torch.cuda.get_device_properties(self.device).total_memory / 1e9:.2f} GB\")\n","            print(f\"GPU Memory Allocated: {torch.cuda.memory_allocated(self.device) / 1e6:.2f} MB\")\n","            print(f\"GPU Memory Cached: {torch.cuda.memory_reserved(self.device) / 1e6:.2f} MB\")\n","\n","    def forward(self, user, item):\n","        user_embedding = self.user_factors(user)\n","        item_embedding = self.item_factors(item)\n","        user_b = self.user_biases(user).flatten()\n","        item_b = self.item_biases(item).flatten()\n","        preds = (user_embedding * item_embedding).sum(1) + user_b + item_b + self.global_bias\n","        return preds\n","\n","    # Fit 方法\n","    def fit(self, train_loader, epochs, lamda, lr, reg):\n","      self.to(self.device)\n","      self.train()\n","      optimizer = torch.optim.Adam(self.parameters(), lr=lr, weight_decay=reg)\n","\n","      for epoch in range(epochs):\n","          total_loss = 0\n","\n","          for users, items, ratings, date_intervals in train_loader:\n","              optimizer.zero_grad()\n","              predictions = self(users, items)\n","              decay_weights = time_decay(date_intervals, lamda)\n","              loss = ((predictions - ratings) ** 2 * decay_weights).mean()\n","              loss.backward()\n","              optimizer.step()\n","              total_loss += loss.item()\n","\n","          print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss / len(train_loader)}\")\n","\n","    def predict(self, user, item):\n","        self.eval()\n","        with torch.no_grad():\n","            prediction = self(user, item)\n","            return prediction.item()"]},{"cell_type":"markdown","metadata":{"id":"N2YD-bWLpd_K"},"source":["## Run"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1733021892766,"user":{"displayName":"Long Haitao","userId":"18227905063443674720"},"user_tz":480},"id":"wRb3J2gGkgQK","outputId":"4817c702-e95f-41d1-e7f6-20ef7300e2e8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model is running on cuda.\n","Running on Tesla T4\n","Total GPU Memory: 15.84 GB\n","GPU Memory Allocated: 565.37 MB\n","GPU Memory Cached: 817.89 MB\n"]}],"source":["model = TimeDecayMF(num_users, num_items, num_factors)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":190180,"status":"ok","timestamp":1733023195638,"user":{"displayName":"Long Haitao","userId":"18227905063443674720"},"user_tz":480},"id":"kvUSt-7UkjZ_","outputId":"875327de-81d8-4c7c-d35f-8a8ab4fdfadb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/8, Loss: 5.312387053680018\n","Epoch 2/8, Loss: 1.8143493325900462\n","Epoch 3/8, Loss: 0.6301023703296253\n","Epoch 4/8, Loss: 0.5060127549402244\n","Epoch 5/8, Loss: 0.5057945774890383\n","Epoch 6/8, Loss: 0.5058017579219497\n","Epoch 7/8, Loss: 0.5057980230500894\n","Epoch 8/8, Loss: 0.5058123532810935\n"]}],"source":["model.fit(train_loader, epochs=5, lamda=0.0002, lr=0.0003, reg=0.02)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"NvnGqOpRq9Ui"},"outputs":[],"source":["def calculate_rmse(model, data_loader):\n","    model.eval()\n","    predictions, ratings = [], []\n","    with torch.no_grad():\n","        for user, item, rating, date_interval in data_loader:\n","            prediction = model(user, item)\n","            predictions.append(prediction.cpu().numpy())\n","            ratings.append(rating.cpu().numpy())\n","    predictions = np.concatenate(predictions)\n","    ratings = np.concatenate(ratings)\n","    return np.sqrt(mean_squared_error(ratings, predictions))"]},{"cell_type":"code","execution_count":88,"metadata":{"id":"r0srFm5rRUvU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733023602624,"user_tz":480,"elapsed":39341,"user":{"displayName":"Long Haitao","userId":"18227905063443674720"}},"outputId":"cfff4480-ec43-4166-e45e-e886bf228f61"},"outputs":[{"output_type":"stream","name":"stdout","text":["Test RMSE: 1.0392874479293823\n"]}],"source":["# 计算测试数据集上的 RMSE\n","test_rmse = calculate_rmse(model, test_loader)\n","print(f\"Test RMSE: {test_rmse}\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","toc_visible":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}