{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59d4459c-c86e-4188-b658-a7c080592cdc",
   "metadata": {},
   "source": [
    "# Factorization Machine (FM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f1a973-3991-4cf3-9a91-252ea917a55b",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "766d7039-62e0-49df-906e-85c11bc11983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5ff984-1e91-475b-803d-be45f647516a",
   "metadata": {},
   "source": [
    "## Data pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c71b9ef9-eb4e-46b5-9b53-03648bb24010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 189992, Number of items: 329340\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "def load_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Map author_id (user) and hotel_id (item) to continuous indices\n",
    "    user_mapping = {id: idx for idx, id in enumerate(df['author_id'].unique())}\n",
    "    item_mapping = {id: idx for idx, id in enumerate(df['hotel_id'].unique())}\n",
    "\n",
    "    df['author_id'] = df['author_id'].map(user_mapping)\n",
    "    df['hotel_id'] = df['hotel_id'].map(item_mapping)\n",
    "\n",
    "    num_users = len(user_mapping)\n",
    "    num_items = len(item_mapping)\n",
    "\n",
    "    return df, num_users, num_items\n",
    "\n",
    "data_file = \"../data/combined_filtered_reviews.csv\"\n",
    "df, num_users, num_items = load_data(data_file)\n",
    "print(f\"Number of users: {num_users}, Number of items: {num_items}\")\n",
    "\n",
    "# Create Dataset and DataLoader\n",
    "class FMDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.users = torch.tensor(df['author_id'].values, dtype=torch.long)\n",
    "        self.items = torch.tensor(df['hotel_id'].values, dtype=torch.long)\n",
    "        self.ratings = torch.tensor(df['rating'].values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.users[idx], self.items[idx], self.ratings[idx]\n",
    "\n",
    "# Split data into train and test sets\n",
    "dataset = FMDataset(df)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5f37f8-b094-4c12-a849-d4a482e09be7",
   "metadata": {},
   "source": [
    "## Define FM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "818154dd-4b1d-4596-b305-7cde7bd33478",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactorizationMachine(nn.Module):\n",
    "    def __init__(self, num_users, num_items, latent_dim=10):\n",
    "        super(FactorizationMachine, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, latent_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, latent_dim)\n",
    "\n",
    "        # Bias terms for user and item\n",
    "        self.user_bias = nn.Embedding(num_users, 1)\n",
    "        self.item_bias = nn.Embedding(num_items, 1)\n",
    "\n",
    "        # Global bias\n",
    "        self.global_bias = nn.Parameter(torch.tensor(0.0))\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        # Embedding lookup\n",
    "        user_emb = self.user_embedding(user)  # Shape: [batch_size, latent_dim]\n",
    "        item_emb = self.item_embedding(item)  # Shape: [batch_size, latent_dim]\n",
    "\n",
    "        # Compute dot product\n",
    "        interaction = torch.sum(user_emb * item_emb, dim=1)\n",
    "\n",
    "        # Add bias terms and global bias\n",
    "        prediction = interaction + self.user_bias(user).squeeze() + self.item_bias(item).squeeze() + self.global_bias\n",
    "\n",
    "        return prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08006b35-2398-424d-85c0-5d08b8af84db",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "156bb9d2-19b6-458d-8ad0-919d4232c308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "latent_dim = 20  # old 10, now using higher values\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "fm_model = FactorizationMachine(num_users, num_items, latent_dim).to(device)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "# optimizer = optim.Adam(fm_model.parameters(), lr=0.01) #old\n",
    "optimizer = optim.Adam(fm_model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2662b133-2e0f-49a2-951d-173db320b8e1",
   "metadata": {},
   "source": [
    "## Traim model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44b79d5f-79e0-43f7-8f6b-3dc754a42b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.0978, Validation Loss: 0.9494\n",
      "Epoch 2, Train Loss: 0.9496, Validation Loss: 0.9489\n",
      "Epoch 3, Train Loss: 0.9495, Validation Loss: 0.9480\n",
      "Epoch 4, Train Loss: 0.9495, Validation Loss: 0.9491\n",
      "Epoch 5, Train Loss: 0.9496, Validation Loss: 0.9487\n",
      "Epoch 6, Train Loss: 0.9496, Validation Loss: 0.9492\n",
      "Epoch 7, Train Loss: 0.9497, Validation Loss: 0.9484\n",
      "Epoch 8, Train Loss: 0.9495, Validation Loss: 0.9482\n",
      "Epoch 9, Train Loss: 0.9494, Validation Loss: 0.9505\n",
      "Epoch 10, Train Loss: 0.9495, Validation Loss: 0.9491\n"
     ]
    }
   ],
   "source": [
    "# Train the FM model\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    fm_model.train()\n",
    "    train_loss = 0\n",
    "    for user, item, rating in train_loader:\n",
    "        user, item, rating = user.to(device), item.to(device), rating.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predictions = fm_model(user, item)\n",
    "        loss = criterion(predictions, rating)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    fm_model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for user, item, rating in test_loader:\n",
    "            user, item, rating = user.to(device), item.to(device), rating.to(device)\n",
    "            predictions = fm_model(user, item)\n",
    "            val_loss += criterion(predictions, rating).item()\n",
    "    val_loss /= len(test_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce1d98c-a25d-4607-94f4-330a2cdf92f3",
   "metadata": {},
   "source": [
    "## Evaluation and RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f85845de-1e52-473d-ab09-59f3d5838d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.9742\n"
     ]
    }
   ],
   "source": [
    "def compute_rmse(model, data_loader):\n",
    "    model.eval()\n",
    "    mse_loss = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for user, item, rating in data_loader:\n",
    "            user, item, rating = user.to(device), item.to(device), rating.to(device)\n",
    "            predictions = model(user, item)\n",
    "            mse_loss += torch.sum((predictions - rating) ** 2).item()\n",
    "            total_samples += len(rating)\n",
    "\n",
    "    rmse = math.sqrt(mse_loss / total_samples)\n",
    "    return rmse\n",
    "\n",
    "test_rmse = compute_rmse(fm_model, test_loader)\n",
    "print(f\"Test RMSE: {test_rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a7f073-ffdf-4c9b-a712-027a47a0a859",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
